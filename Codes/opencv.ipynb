{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skull stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\" Load an image from a specified path. \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(\"Image could not be read. Check the path.\")\n",
    "    return image\n",
    "\n",
    "def create_skull_mask(image):\n",
    "    \"\"\" Create a mask to remove skull by setting skull pixels to 0 and all other to 1. \"\"\"\n",
    "    # Assuming skull pixels are exactly 255\n",
    "    skull_mask = np.where(image == 255, 0, 1).astype('uint8')\n",
    "    return skull_mask\n",
    "\n",
    "def apply_mask(image, mask):\n",
    "    \"\"\" Apply the created mask to the original image to isolate brain and vessels. \"\"\"\n",
    "    brain_and_vessels = cv2.multiply(image, mask)\n",
    "    return brain_and_vessels\n",
    "\n",
    "def save_image(image, output_path):\n",
    "    \"\"\" Save the processed image to a specified path. \"\"\"\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "def display_image(image, window_name='Image'):\n",
    "    \"\"\" Display an image until a key is pressed. \"\"\"\n",
    "    cv2.imshow(window_name, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    image_path = f\"/Users/selimgul/Desktop/photos/{image_number}_resized.png\"\n",
    "    output_path = f'/Users/selimgul/Desktop/photos/{image_number}_brain_vessels.png'\n",
    "    \n",
    "    # Load the original grayscale image\n",
    "    image = load_image(image_path)\n",
    "    \n",
    "    # Create a mask to remove the skull\n",
    "    skull_mask = create_skull_mask(image)\n",
    "    \n",
    "    # Apply the mask to the original image to remove the skull\n",
    "    brain_and_vessels = apply_mask(image, skull_mask)\n",
    "    \n",
    "    # Save the resultant image\n",
    "    save_image(brain_and_vessels, output_path)\n",
    "    \n",
    "    # Display the resultant image\n",
    "    display_image(brain_and_vessels, 'Brain and Vessels')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Image - Min HU: 2, Max HU: 247, Mean HU: 42.14890670776367, Std HU: 54.71201907190469\n",
      "Vessel Image - Min HU: 0, Max HU: 255, Mean HU: 63.678016662597656, Std HU: 110.3766480868138\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    # Load the image in grayscale mode\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(\"Error: Image could not be read. Check the path.\")\n",
    "        exit()\n",
    "\n",
    "    # Apply Gaussian Blur\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(blurred_image)\n",
    "\n",
    "    return enhanced_image\n",
    "\n",
    "def apply_thresholds(enhanced_image):\n",
    "    # Set threshold values\n",
    "    vessel_hu_min = 75  # Lower bound for blood vessels\n",
    "    vessel_hu_max = 200  # Upper bound avoiding bones\n",
    "\n",
    "    # Apply thresholds\n",
    "    _, lower_thresh_image = cv2.threshold(enhanced_image, vessel_hu_min, 255, cv2.THRESH_BINARY)\n",
    "    _, upper_thresh_image = cv2.threshold(enhanced_image, vessel_hu_max, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Combine the thresholds to isolate the vessels\n",
    "    vessel_image = cv2.bitwise_and(lower_thresh_image, upper_thresh_image)\n",
    "    return vessel_image\n",
    "\n",
    "def apply_adaptive_thresholds(enhanced_image):\n",
    "    # Apply adaptive threshold\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(\n",
    "        enhanced_image,  # Source image\n",
    "        255,  # Maximum value to use with the THRESH_BINARY and THRESH_BINARY_INV thresholding types\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,  # Adaptive method - using Gaussian (weighted sum of neighbourhood values)\n",
    "        cv2.THRESH_BINARY_INV,  # Thresholding type\n",
    "        11,  # Block size - size of a pixel neighborhood used to calculate a threshold value\n",
    "        2   # Constant subtracted from the mean or weighted mean\n",
    "    )\n",
    "    return adaptive_thresh\n",
    "\n",
    "\n",
    "def display_images(images):\n",
    "    # Display each image in the dictionary\n",
    "    for title, img in images.items():\n",
    "        cv2.imshow(title, img)\n",
    "        print(f\"{title} - Min HU: {np.min(img)}, Max HU: {np.max(img)}, Mean HU: {np.mean(img)}, Std HU: {np.std(img)}\")\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    image_path = f'/Users/selimgul/Desktop/photos/{image_number}_brain_vessels.png'\n",
    "    enhanced_image = load_and_preprocess_image(image_path)\n",
    "    vessel_image = apply_adaptive_thresholds(enhanced_image)\n",
    "\n",
    "    #save vessel image\n",
    "    output_path = f'/Users/selimgul/Desktop/photos/{image_number}_vessels.png'\n",
    "    cv2.imwrite(output_path, vessel_image)\n",
    "\n",
    "    images = {\n",
    "        \"Enhanced Image\": enhanced_image,\n",
    "        \"Vessel Image\": vessel_image,\n",
    "    }\n",
    "    \n",
    "    display_images(images)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Image - Min HU: 0, Max HU: 255, Mean HU: 68.69857747020377, Std HU: 84.24398649042426\n",
      "Vessel Image - Min HU: 0, Max HU: 255, Mean HU: 66.04705882352941, Std HU: 111.71296263532378\n",
      "Processed Vessel Image - Min HU: 0, Max HU: 255, Mean HU: 63.207843137254905, Std HU: 110.10344484136803\n",
      "Filtered Vessel Image - Min HU: 0, Max HU: 255, Mean HU: 62.09803921568628, Std HU: 109.44785756499344\n",
      "Vessel Edges - Min HU: 0, Max HU: 255, Mean HU: 6.858823529411764, Std HU: 41.25477596342498\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    # Load the image in grayscale mode\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Error: Image could not be read. Check the path.\")\n",
    "    \n",
    "    # Apply Gaussian Blur\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Apply Histogram Equalization\n",
    "    equalized_image = cv2.equalizeHist(blurred_image)\n",
    "\n",
    "    return equalized_image\n",
    "\n",
    "def apply_thresholds(image):\n",
    "    # Set threshold values\n",
    "    vessel_hu_min = 75  # Lower bound for blood vessels\n",
    "    vessel_hu_max = 200  # Upper bound avoiding bones\n",
    "\n",
    "    # Apply thresholds\n",
    "    _, lower_thresh_image = cv2.threshold(image, vessel_hu_min, 255, cv2.THRESH_BINARY)\n",
    "    _, upper_thresh_image = cv2.threshold(image, vessel_hu_max, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Combine the thresholds to isolate the vessels\n",
    "    vessel_image = cv2.bitwise_and(lower_thresh_image, upper_thresh_image)\n",
    "    return vessel_image\n",
    "\n",
    "def clean_and_label_vessels(vessel_image):\n",
    "    # Apply morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    cleaned_vessel_image = cv2.morphologyEx(vessel_image, cv2.MORPH_OPEN, kernel)\n",
    "    cleaned_vessel_image = cv2.morphologyEx(cleaned_vessel_image, cv2.MORPH_CLOSE, kernel)\n",
    "    return cleaned_vessel_image\n",
    "\n",
    "def connected_components_analysis(image):\n",
    "    # Perform connected components analysis\n",
    "    num_labels, labels_im = cv2.connectedComponents(image)\n",
    "    min_size = 50\n",
    "    filtered_labels_im = np.zeros_like(labels_im, dtype=np.uint8)\n",
    "    for i in range(1, num_labels):\n",
    "        if np.sum(labels_im == i) > min_size:\n",
    "            filtered_labels_im[labels_im == i] = 255\n",
    "    return filtered_labels_im\n",
    "\n",
    "def edge_detection(image):\n",
    "    # Apply edge detection using Canny\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    return edges\n",
    "\n",
    "def display_images(images):\n",
    "    # Display each image in the dictionary\n",
    "    for title, img in images.items():\n",
    "        cv2.imshow(title, img)\n",
    "        print(f\"{title} - Min HU: {np.min(img)}, Max HU: {np.max(img)}, Mean HU: {np.mean(img)}, Std HU: {np.std(img)}\")\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main(image_number):\n",
    "    image_path = f'/Users/selimgul/Desktop/photos/{image_number}_brain_vessels.png'\n",
    "    enhanced_image = load_and_preprocess_image(image_path)\n",
    "    vessel_image = apply_thresholds(enhanced_image)\n",
    "    cleaned_vessel_image = clean_and_label_vessels(vessel_image)\n",
    "\n",
    "    # Apply connected components analysis to extract vessels\n",
    "    filtered_labels_im = connected_components_analysis(cleaned_vessel_image)\n",
    "\n",
    "    # Apply edge detection to extract vessel boundaries\n",
    "    edges = edge_detection(filtered_labels_im)\n",
    "\n",
    "    #save the vessel image\n",
    "    cv2.imwrite(f'/Users/selimgul/Desktop/photos/{image_number}_vessel_image.png', cleaned_vessel_image)\n",
    "\n",
    "    images = {\n",
    "        \"Enhanced Image\": enhanced_image,\n",
    "        \"Vessel Image\": vessel_image,\n",
    "        \"Processed Vessel Image\": cleaned_vessel_image,\n",
    "        \"Filtered Vessel Image\": filtered_labels_im,\n",
    "        \"Vessel Edges\": edges\n",
    "    }\n",
    "    \n",
    "    display_images(images)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(image_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI Selected - Coordinates: (99, 79) to (69, 69)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to handle mouse events\n",
    "def click_and_crop(event, x, y, flags, param):\n",
    "    # Reference to the global variables\n",
    "    global roi, cropping, image\n",
    "\n",
    "    # Start the cropping with a mouse click\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        roi = [(x, y)]\n",
    "        cropping = True\n",
    "\n",
    "    # Finish the cropping with mouse release, draw rectangle, and show coordinates\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        roi.append((x, y))\n",
    "        cropping = False\n",
    "        cv2.rectangle(image, roi[0], (x, y), (0, 255, 0), 2)\n",
    "        cv2.imshow(\"image\", image)\n",
    "        print(\"ROI Selected - Coordinates: ({}, {}) to ({}, {})\".format(roi[0][0], roi[0][1], abs(roi[0][0] - x), abs(roi[0][1] - y)))\n",
    "        cv2.waitKey(500)  # Display for 500 ms then close automatically\n",
    "        cv2.destroyWindow(\"image\")\n",
    "\n",
    "def main():\n",
    "    global image\n",
    "    image_path = f\"/Users/selimgul/Desktop/photos/{image_number}_enhanced_image.png\"  # Change to your image path\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error loading image\")\n",
    "        return\n",
    "\n",
    "    cv2.namedWindow(\"image\")\n",
    "    cv2.setMouseCallback(\"image\", click_and_crop)\n",
    "\n",
    "    # Display the image and wait until user finishes selecting the ROI\n",
    "    cv2.imshow(\"image\", image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_image(path):\n",
    "    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image could not be read. Check the path.\")\n",
    "    return image\n",
    "\n",
    "def apply_clahe(image, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    return clahe.apply(image)\n",
    "\n",
    "def threshold_image(image, low_thresh, high_thresh):\n",
    "    _, low = cv2.threshold(image, low_thresh, 255, cv2.THRESH_BINARY)\n",
    "    _, high = cv2.threshold(image, high_thresh, 255, cv2.THRESH_BINARY_INV)\n",
    "    return cv2.bitwise_and(low, high)\n",
    "\n",
    "def clean_image(image, kernel_size=(1, 1), operation_iter=1):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)\n",
    "    opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel, iterations=operation_iter)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=operation_iter)\n",
    "    return closing\n",
    "\n",
    "def remove_small_objects(image, min_size):\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image)\n",
    "    output = np.zeros_like(labels, dtype=np.uint8)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_size:\n",
    "            output[labels == i] = 255\n",
    "    return output\n",
    "\n",
    "def main():\n",
    "    image_path = f'/Users/selimgul/Desktop/photos/{image_number}_brain_vessels.png'\n",
    "    image = load_image(image_path)\n",
    "\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    enhanced_image = apply_clahe(blurred_image)\n",
    "\n",
    "    vessel_image = threshold_image(enhanced_image, 110, 200)\n",
    "    cleaned_vessel_image = clean_image(vessel_image, kernel_size=(3, 3), operation_iter=2)\n",
    "    final_vessel_image = remove_small_objects(cleaned_vessel_image, min_size=50)\n",
    "\n",
    "    #Save enhanced and vessel image\n",
    "    output_path = f'/Users/selimgul/Desktop/photos/{image_number}_enhanced_image.png'\n",
    "    cv2.imwrite(output_path, enhanced_image)\n",
    "\n",
    "    output_path = f'/Users/selimgul/Desktop/photos/{image_number}_vessel_image.png'\n",
    "    cv2.imwrite(output_path, vessel_image)\n",
    "\n",
    "    output_path = f'/Users/selimgul/Desktop/photos/{image_number}_cleaned_vessel_image.png'\n",
    "    cv2.imwrite(output_path, cleaned_vessel_image)\n",
    "\n",
    "    output_path = f'/Users/selimgul/Desktop/photos/{image_number}_final_vessel_image.png'\n",
    "    cv2.imwrite(output_path, final_vessel_image)\n",
    "\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('CLAHE Enhanced Image', enhanced_image)\n",
    "    cv2.imshow('Vessel Image', vessel_image)\n",
    "    cv2.imshow('Cleaned Vessel Image', cleaned_vessel_image)\n",
    "    cv2.imshow('Final Vessel Image', final_vessel_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics within ROI:\n",
      "Mean Gradient Magnitude: 368.9435027817831\n",
      "Standard Deviation of Gradient Magnitude: 203.23661943980352\n",
      "Area of Significant Changes (in pixels): 8649\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def analyze_vessel_intensity(enhanced_image, vessel_mask, roi_coords):\n",
    "    x, y, w, h = roi_coords\n",
    "    vessel_roi = vessel_mask[y:y+h, x:x+w]\n",
    "    enhanced_roi = enhanced_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Apply the vessel mask to the enhanced ROI to focus on vessel intensities\n",
    "    vessel_intensity = cv2.bitwise_and(enhanced_roi, enhanced_roi, mask=vessel_roi)\n",
    "\n",
    "    # Calculate the gradient magnitude\n",
    "    grad_x = cv2.Sobel(vessel_intensity, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(vessel_intensity, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    grad_mag = cv2.magnitude(grad_x, grad_y)\n",
    "\n",
    "    # Threshold the gradient to identify significant changes\n",
    "    _, significant_changes = cv2.threshold(grad_mag, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Overlay the significant changes on the original enhanced image\n",
    "    overlay = enhanced_image.copy()\n",
    "    overlay[y:y+h, x:x+w][significant_changes > 0] = 255  # Highlight changes\n",
    "\n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'mean': np.mean(grad_mag[significant_changes > 0]),\n",
    "        'std_dev': np.std(grad_mag[significant_changes > 0]),\n",
    "        'change_area': np.count_nonzero(significant_changes > 0)\n",
    "    }\n",
    "\n",
    "    return overlay, stats\n",
    "\n",
    "# Load images\n",
    "enhanced_image = cv2.imread(f'/Users/selimgul/Desktop/photos/{image_number}_enhanced_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "vessel_mask = cv2.imread(f'/Users/selimgul/Desktop/photos/{image_number}_vessel_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define ROI coordinates (x, y, width, height)\n",
    "roi_coords = 157, 202, 155, 207  # Example values\n",
    "\n",
    "# Perform analysis\n",
    "overlay_image, stats = analyze_vessel_intensity(enhanced_image, vessel_mask, roi_coords)\n",
    "\n",
    "# Display significant changes overlaid on the original image\n",
    "cv2.imshow('Overlay of Significant Changes on Enhanced Image', overlay_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print statistical analysis\n",
    "print(\"Statistics within ROI:\")\n",
    "print(\"Mean Gradient Magnitude:\", stats['mean'])\n",
    "print(\"Standard Deviation of Gradient Magnitude:\", stats['std_dev'])\n",
    "print(\"Area of Significant Changes (in pixels):\", stats['change_area'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    image_number = 3  # example number\n",
    "    image_path = f'/Users/selimgul/Desktop/photos/{image_number}_enhanced_image.png'\n",
    "    vessel_mask_path = f'/Users/selimgul/Desktop/photos/{image_number}_vessel_image.png'\n",
    "    \n",
    "    enhanced_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    vessel_mask = cv2.imread(vessel_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if enhanced_image is None or vessel_mask is None:\n",
    "        print(\"Error loading images\")\n",
    "        return\n",
    "\n",
    "    # Ensure the vessel mask is binary for proper visualization\n",
    "    _, vessel_mask = cv2.threshold(vessel_mask, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Create a color version of the enhanced image to overlay the vessels in color\n",
    "    color_enhanced_image = cv2.cvtColor(enhanced_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Overlay vessel mask in red on the enhanced image\n",
    "    color_enhanced_image[vessel_mask == 255] = [0, 0, 255]  # BGR format for red\n",
    "\n",
    "    # Display the overlay image\n",
    "    cv2.imshow('Overlay of Vessels on Enhanced Image', color_enhanced_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the greyscale values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "64\n",
      "84\n",
      "76\n",
      "131\n",
      "84\n",
      "77\n",
      "75\n",
      "77\n",
      "90\n",
      "79\n",
      "88\n",
      "79\n",
      "63\n",
      "73\n",
      "74\n",
      "74\n",
      "75\n",
      "75\n",
      "55\n",
      "112\n",
      "80\n",
      "84\n",
      "89\n",
      "81\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path = f\"/Users/selimgul/Desktop/photos/{image_number}_enhanced_image.png\"\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Display the image and use OpenCV's built-in functionality to click and see pixel values\n",
    "cv2.imshow('Click on the skull to see pixel values', image)\n",
    "cv2.setMouseCallback('Click on the skull to see pixel values', lambda event, x, y, flags, param: print(image[y, x]) if event == cv2.EVENT_LBUTTONDOWN else None)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Alternatively, generate a histogram of the grayscale values\n",
    "plt.hist(image.ravel(), 256, [0, 256])\n",
    "plt.title('Histogram of Grayscale Values')\n",
    "plt.show()\n",
    "\n",
    "# Analyze the histogram to estimate where the skull might be\n",
    "# Typically, you will see a peak at the higher end of the grayscale values\n",
    "# Adjust the range below according to your observations\n",
    "possible_skull_intensity_range = (180, 255)  # This is an example range, adjust it according to your histogram\n",
    "\n",
    "# Apply threshold to visualize the estimated skull area\n",
    "_, skull_mask = cv2.threshold(image, possible_skull_intensity_range[0], possible_skull_intensity_range[1], cv2.THRESH_BINARY)\n",
    "cv2.imshow('Estimated Skull Area', skull_mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since I can't view images or specific URLs including \"https://ibb.co/MRTFKw4\", I will base my response on a typical scenario of what you described—a CT scan of a brain with an area marked in red to indicate an occlusion.\n",
      "\n",
      "1. **Understanding the Image**: The CT scan you're referring to shows an image of a brain, and typically such scans are used medically to view the internal structures of the skull. This can help identify issues like bleeding, tumors, or blockages.\n",
      "\n",
      "2. **Identifying the Occlusion**: In medical terms, an \"occlusion\" usually refers to the blockage of a blood vessel. When a tool that you developed marks an area in red, it highlights the area on the CT scan where an occlusion is detected. The primary reason to mark such an area is to isolate and identify the specific location and extent of the blockage.\n",
      "\n",
      "3. **Implications of the Output**:\n",
      "   - **Medical Diagnosis**: The red mark helps medical professionals quickly and clearly identify where the blockage is, which is crucial in diagnosing conditions like ischemic strokes, where blood flow to a part of the brain is blocked. Immediate and accurate identification enhances the efficiency of medical diagnosis and the subsequent treatment plan.\n",
      "   - **Treatment Planning**: Depending on the location and size of the occlusion, treatments might vary. Common responses to a stroke include medications like blood thinners, clot retrieval, or surgery. Imaging marked by your tool could be used to make these decisions more quickly and accurately.\n",
      "\n",
      "4. **Technical Insight**: The red marking on the image, facilitated by a Python tool, suggests the use of image processing techniques—possibly involving algorithms that detect changes in tissue density or other markers that signify an occlusion. Such a tool likely utilizes libraries from Python’s scientific stack like NumPy, SciPy, or an image processing library like OpenCV.\n",
      "\n",
      "This output image, essentially, would mean that there is an area in the brain that has blocked blood supply, and the red marking is instrumental in the medical diagnostic process to determine the next steps in healthcare management. The tool’s output thus plays a vital role in speeding up emergency medical responses and enhancing patient outcomes in conditions like stroke."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = \"\"\n",
    "image_url = \"https://ibb.co/MRTFKw4\"\n",
    "\n",
    "question = input(\"Ask a question about the image\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": f\"The following is a CT scan image of a brain: {image_url}\\n\\n Answer the question about this image:{question}\",}],\n",
    "    stream=True,\n",
    "    model=\"gpt-4-turbo\",\n",
    ")\n",
    "\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize image to 255x255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def resize_image(image_path, output_size=(255, 255)):\n",
    "    # Load the image from the specified path\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(\"The image file was not found.\")\n",
    "\n",
    "    # Resize the image to the output_size\n",
    "    resized_image = cv2.resize(image, output_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "image_path = f'/Users/selimgul/Desktop/photos/{image_number}.png'  # Replace this with your image's path\n",
    "resized_image = resize_image(image_path)\n",
    "\n",
    "# If you want to display the resized image\n",
    "cv2.imshow(\"Resized Image\", resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# If you want to save the resized image\n",
    "output_image_path = f'/Users/selimgul/Desktop/photos/{image_number}_resized.png'  # Replace with your desired output path\n",
    "cv2.imwrite(output_image_path, resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance around vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean intensity inside edges: 108.60121765601217\n",
      "Mean intensity outside edges: 84.75454545454545\n",
      "Intensity difference: 23.846672201466717\n",
      "No significant occlusion detected\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_edges(image):\n",
    "    \"\"\"Detect edges using the Sobel operator.\"\"\"\n",
    "    grad_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    grad_mag = cv2.magnitude(grad_x, grad_y)\n",
    "    _, edge_mask = cv2.threshold(grad_mag, 50, 255, cv2.THRESH_BINARY)\n",
    "    return edge_mask.astype(np.uint8)  # Ensure mask is binary type uint8\n",
    "\n",
    "def dilate_edges(edge_mask, kernel_size=(5,5)):\n",
    "    \"\"\"Dilate edges to include adjacent tissue areas in the analysis.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)\n",
    "    dilated_edges = cv2.dilate(edge_mask, kernel, iterations=1)\n",
    "    return dilated_edges\n",
    "\n",
    "def compare_intensities(image, dilated_edges, original_edges):\n",
    "    \"\"\"Calculate mean intensity inside and just outside the vessel edges.\"\"\"\n",
    "    # Ensure masks are binary and type uint8\n",
    "    outside_mask = cv2.subtract(dilated_edges, original_edges).astype(np.uint8)\n",
    "    \n",
    "    inside_intensity = cv2.mean(image, mask=original_edges)[0]\n",
    "    outside_intensity = cv2.mean(image, mask=outside_mask)[0]\n",
    "    \n",
    "    intensity_difference = abs(inside_intensity - outside_intensity)\n",
    "    \n",
    "    return inside_intensity, outside_intensity, intensity_difference\n",
    "\n",
    "# Load the image\n",
    "enhanced_image = cv2.imread('/Users/selimgul/Desktop/photos/12_enhanced_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "x, y, width, height = 99, 79, 69, 69\n",
    "\n",
    "\n",
    "# Validate ROI dimensions\n",
    "if y + height > enhanced_image.shape[0] or x + width > enhanced_image.shape[1]:\n",
    "    raise ValueError(\"ROI dimensions exceed the image dimensions.\")\n",
    "\n",
    "# Extract the ROI from the image\n",
    "enhanced_roi = enhanced_image[y:y+height, x:x+width]\n",
    "\n",
    "# Edge detection and dilation\n",
    "edge_mask = detect_edges(enhanced_roi)\n",
    "dilated_edges = dilate_edges(edge_mask)\n",
    "\n",
    "# Intensity comparison\n",
    "inside_int, outside_int, diff = compare_intensities(enhanced_roi, dilated_edges, edge_mask)\n",
    "print(\"Mean intensity inside edges:\", inside_int)\n",
    "print(\"Mean intensity outside edges:\", outside_int)\n",
    "print(\"Intensity difference:\", diff)\n",
    "\n",
    "# Threshold to detect significant changes\n",
    "significant_change_threshold = 27\n",
    "if diff > significant_change_threshold:\n",
    "    print(\"Significant occlusion detected\")\n",
    "else:\n",
    "    print(\"No significant occlusion detected\")\n",
    "\n",
    "significant_mask = np.zeros_like(enhanced_image, dtype=np.uint8)\n",
    "significant_mask[y:y+height, x:x+width] = dilated_edges\n",
    "\n",
    "color_enhanced_image = cv2.cvtColor(enhanced_image, cv2.COLOR_GRAY2BGR)\n",
    "color_enhanced_image[significant_mask == 255] = [0, 0, 255]  # Highlight changes in red\n",
    "\n",
    "\n",
    "# Display images\n",
    "cv2.imshow('Enhanced Image', enhanced_image)\n",
    "cv2.imshow('Enhanced ROI', enhanced_roi)\n",
    "cv2.imshow('Edge Mask', edge_mask)\n",
    "cv2.imshow('Dilated Edges', dilated_edges)\n",
    "cv2.imshow('Significant Changes Overlay on Enhanced Image', color_enhanced_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate_edges(edge_mask, kernel_size=(5,5)):\n",
    "    \"\"\"Dilate edges to include adjacent tissue areas in the analysis.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)\n",
    "    dilated_edges = cv2.dilate(edge_mask, kernel, iterations=1)\n",
    "    return dilated_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_significant_differences(image, dilated_edges, original_edges, threshold):\n",
    "    \"\"\"Calculate absolute intensity difference for each pixel and create a visualization mask.\"\"\"\n",
    "    # Calculate the absolute intensity difference for each pixel\n",
    "    intensity_difference = cv2.absdiff(cv2.blur(image, (3, 3)), cv2.blur(image, (5, 5)))\n",
    "    \n",
    "    # Create a mask based on the threshold\n",
    "    _, significant_mask = cv2.threshold(intensity_difference, threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Apply the dilated edges mask to focus only on regions around the edges\n",
    "    significant_mask = cv2.bitwise_and(significant_mask, significant_mask, mask=dilated_edges - original_edges)\n",
    "    \n",
    "    return significant_mask\n",
    "\n",
    "def clean_and_label_vessels(vessel_image):\n",
    "    # Apply morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    cleaned_vessel_image = cv2.morphologyEx(vessel_image, cv2.MORPH_OPEN, kernel)\n",
    "    cleaned_vessel_image = cv2.morphologyEx(cleaned_vessel_image, cv2.MORPH_CLOSE, kernel)\n",
    "    return cleaned_vessel_image\n",
    "\n",
    "def display_images(images):\n",
    "    # Display each image in the dictionary\n",
    "    for title, img in images.items():\n",
    "        cv2.imshow(title, img)\n",
    "        print(f\"{title} - Min HU: {np.min(img)}, Max HU: {np.max(img)}, Mean HU: {np.mean(img)}, Std HU: {np.std(img)}\")\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "def calculate_differences(image, rois):\n",
    "    differences = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        local_mean = cv2.blur(roi, (5,5))  # Example local mean computation\n",
    "        diff = np.abs(roi - local_mean)\n",
    "        differences.append(diff.flatten())\n",
    "    return differences\n",
    "\n",
    "def perform_statistical_test(differences):\n",
    "    f_val, p_val = f_oneway(*differences)\n",
    "    return f_val, p_val\n",
    "\n",
    "def detect_edges(image):\n",
    "    \"\"\"Detect edges using the Sobel operator within the ROI.\"\"\"\n",
    "    grad_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    grad_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    grad_mag = cv2.magnitude(grad_x, grad_y)\n",
    "    _, edge_mask = cv2.threshold(grad_mag, 50, 255, cv2.THRESH_BINARY)\n",
    "    return edge_mask.astype(np.uint8)\n",
    "\n",
    "def dilate_edges(edge_mask, kernel_size=(3,3)):\n",
    "    \"\"\"Dilate edges to include just outside the vessel edges within the ROI.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)\n",
    "    dilated_edges = cv2.dilate(edge_mask, kernel, iterations=1)\n",
    "    return dilated_edges\n",
    "\n",
    "def calculate_significant_differences(image, dilated_edges, original_edges, threshold):\n",
    "    \"\"\"Calculate significant differences at the pixel level and create a mask within the ROI.\"\"\"\n",
    "    # Create masks for inside and just outside the vessel edges\n",
    "    inside_mask = original_edges.astype(np.uint8)\n",
    "    outside_mask = cv2.subtract(dilated_edges, original_edges).astype(np.uint8)\n",
    "    \n",
    "    # Calculate pixel-wise intensity differences where the masks are applied\n",
    "    intensity_difference = cv2.absdiff(cv2.bitwise_and(image, image, mask=inside_mask),\n",
    "                                       cv2.bitwise_and(image, image, mask=outside_mask))\n",
    "    \n",
    "    # Apply a threshold to find significant differences\n",
    "    _, significant_mask = cv2.threshold(intensity_difference, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return significant_mask\n",
    "\n",
    "# Load the image\n",
    "enhanced_image = cv2.imread(f'/Users/selimgul/Desktop/photos/{image_number}_enhanced_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "if enhanced_image is None:\n",
    "    raise FileNotFoundError(\"Image could not be read. Check the path.\")\n",
    "\n",
    "x, y, width, height = 90, 90, 39, 53  # Define the coordinates of your ROI\n",
    "enhanced_roi = enhanced_image[y:y+height, x:x+width]  # Extract the ROI\n",
    "\n",
    "#ROIs should be adjusted according to the image\n",
    "rois = [(10, 10, 50, 50), (70, 70, 50, 50), (130, 130, 50, 50)]\n",
    "differences = calculate_differences(image, rois)\n",
    "f_val, p_val = perform_statistical_test(differences)\n",
    "\n",
    "print(\"ANOVA F-value:\", f_val)\n",
    "print(\"ANOVA P-value:\", p_val)\n",
    "\n",
    "if p_val < 0.05: \n",
    "    print(\"Significant differences found between ROIs\")\n",
    "    # Edge detection and dilation within the ROI\n",
    "    edge_mask = detect_edges(enhanced_roi)\n",
    "    dilated_edges = dilate_edges(edge_mask)\n",
    "\n",
    "    # Find significant differences within the ROI\n",
    "    significant_change_threshold = 180  # Define your specific intensity difference threshold\n",
    "    significant_mask = calculate_significant_differences(enhanced_roi, dilated_edges, edge_mask, significant_change_threshold)\n",
    "\n",
    "    # Create a full-size mask to overlay on the original enhanced image\n",
    "    full_size_mask = np.zeros_like(enhanced_image, dtype=np.uint8)\n",
    "    full_size_mask[y:y+height, x:x+width] = significant_mask  # Place the ROI mask back into the full image context\n",
    "\n",
    "    # Overlay significant changes on the original image\n",
    "    color_enhanced_image = cv2.cvtColor(enhanced_image, cv2.COLOR_GRAY2BGR)\n",
    "    color_enhanced_image[full_size_mask == 255] = [0, 0, 255]  # Highlight significant changes in red\n",
    "\n",
    "    #output color enhanced image\n",
    "    output_path = f'/Users/selimgul/Desktop/photos/{image_number}_color_enhanced_image.png'\n",
    "    cv2.imwrite(output_path, color_enhanced_image)\n",
    "\n",
    "    # Display images\n",
    "    cv2.imshow('Original Image', enhanced_image)\n",
    "    cv2.imshow('Significant Changes Overlay', color_enhanced_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No significant differences found between ROIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
